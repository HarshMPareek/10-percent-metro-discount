---
title: "Does Metro's 10% Student Discount Actually Save Students Money or Is It Just Marketing?"
subtitle: "A Comparative Analysis of Grocery Prices Near the University of Toronto"
author: 
  - Harsh M Pareek
thanks: "Code and data are available at: [https://github.com/HarshMPareek/10-percent-metro-discount](https://github.com/HarshMPareek/10-percent-metro-discount)."
date: today
date-format: long
abstract: "This paper analyzes grocery prices and student discounts at five supermarkets near the University of Toronto: Metro, Loblaws, No Frills, Galleria, and T&T. Four of these stores offer student discounts, excluding T&T. Our study suggests that while Metro's 10% student discount lowers costs, other factors like additional promotions at other stores and convenience affect overall savings. This analysis helps students determine which supermarket offers the best value when considering discounts and personal shopping habits."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(knitr)
library(kableExtra)
library(rstanarm)
library(broom)
library(arrow)      # For reading Parquet files if needed
library(here)       # For file paths
library(patchwork)  # For combining ggplots
library(modelsummary)
library(bayesplot)
library(viridis)
library(cowplot)
library(stringr)

# Load the data
grocery_data <- read_parquet(here("data/02-analysis_data/cleaned_products_with_prices.parquet"))

# Load the fitted model
model <- readRDS(file = here::here("models/price_model_stanarm.rds"))

```


# Introduction

Grocery expenses are a significant concern for university students, especially in high-cost cities like Toronto. Students at the University of Toronto (UofT) often have limited budgets and need to make strategic decisions to minimize their living expenses. Supermarkets near the UofT campus recognize this and frequently offer discounts to attract student customers. Metro, a major grocery chain, advertises a straightforward 10% student discount, potentially offering substantial savings.

Our analysis involves collecting and cleaning price data from these five supermarkets, categorizing products into staples, proteins, dairy, vegetables, fruits, snacks, condiments, spices, frozen essentials, and baking basics. We performed exploratory data analysis and fitted a linear regression model to assess the effect of vendor and product category on current prices. The results indicate that while Metro's student discount reduces prices, competitors like No Frills often have lower base prices that result in overall lower costs for students. In some categories, Metro becomes competitive when the discount is applied, but in others, students may achieve greater savings elsewhere.

Understanding these pricing dynamics is crucial for students managing tight budgets. By clarifying whether Metro's student discount translates into real savings, we provide valuable insights that can help students make informed decisions about where to shop for groceries, ultimately impacting their financial well-being during their studies.

## Estimand
We aim to estimate whether Metro's 10% student discount actually results in lower grocery expenses for students compared to other nearby supermarkets that may offer lower base prices but no direct student discounts. Specifically, we investigate how Metro's discounted prices compare to those of No Frills, Loblaws, Galleria, and T&T Supermarket across various product categories commonly purchased by students.


The remainder of this paper is structured as follows. In Section @sec-data, we describe the data collection and cleaning process. Section @sec-model details the statistical model and its results. Section @sec-discussion discusses the implications of our findings. Finally there is also an apendix attached.


# Data {#sec-data}

## Data Source and Context
We used a dataset of grocery prices from five supermarkets near the University of Toronto (UofT) to assess whether Metro's 10% student discount reduces grocery costs:

- Metro
- No Frills
- Loblaws
- Galleria
- T&T Supermarket

The data were sourced from Project Hammer [@Filipp2024], an initiative providing a comprehensive database of historical grocery prices to enhance competition in the Canadian grocery sector. This dataset includes product-level pricing information from eight vendors, allowing detailed comparisons across retailers but we only selected five which were available near the campus.

## Dataset Characteristics
- Time Frame: February 28, 2024 to November 29, 2024.
- Data Files:
  - Product File: Contains metadata and product details.
  - Raw File: Contains time-series price data.
  
This dataset was chosen because it directly aligned with scope of study and already had a lot of information that I needed for this study. Other datasets were either too complicated to work with or did not have enough data.

```{r}
#| include: false
#| warning: false
#| message: false

# Preview the data structure
glimpse(grocery_data)

```

## Measurement

The dataset comprises five key variables:

- **Product ID (`product_id`)**: A unique identifier for each product, ensuring distinct reference across observations.

- **Product Name (`product_name`)**: The name and description of the product as presented to consumers (e.g., "Organic Whole Milk 1L").

- **Category (`category`)**: Assigned category based on product characteristics, such as staples, proteins, dairy, etc.

- **Vendor (`vendor`)**: The supermarket where the product is sold.

- **Current Price (`current_price`)**: The latest available price of the product in Canadian dollars (CAD).

### Mapping Real-World to Dataset Entries

Each entry in the dataset corresponds to a specific product available in one of the selected supermarkets. The process from real-world observation to dataset entry involved:

- **Identification**: Assigning a unique product_id to each product.

- **Description**: Capturing the product_name as listed by the vendor.

- **Categorization**: Assigning each product to one of ten predefined categories using keyword matching while applying exclusion criteria to prevent misclassification.

- **Pricing**: Extracting the current_price directly from the product listing, converted to a numeric format for analysis.

**Unit of Measurement**
- Numerical Data: current_price is measured in Canadian dollars (CAD) and is a positive numeric value.

- Categorical Data: vendor and category are categorical variables with no inherent units, used to group and compare products based on the supermarket and product type.

**Data Considerations**
- Sampling and Coverage: The dataset focuses on frequently purchased items, potentially excluding niche products.
- Data Integrity: Measures were taken to eliminate duplicates and handle missing data, though some inconsistencies may persist.
- Temporal Dynamics: Pricing reflects specific points in time, subject to promotions and seasonal changes.
All data processing and analysis were conducted using R [@citeR] and the tidyverse [@thereferencecanbewhatever].


## Product Categories

Products were categorized based on common grocery items typically purchased by students:

- **Staples**: Rice, pasta, bread, and other essential grains.
- **Proteins**: Meat, poultry, fish, eggs, tofu, and legumes.
- **Dairy**: Milk, cheese, yogurt, and dairy alternatives.
- **Vegetables**: Fresh produce like spinach, broccoli, and carrots.
- **Fruits**: Apples, bananas, berries, and other fruits.
- **Snacks**: Nuts, granola bars, popcorn, and similar items.
- **Condiments**: Sauces, oils, vinegar, and seasonings.
- **Spices**: Herbs and spices used in cooking.
- **Frozen Essentials**: Frozen fruits, vegetables, and pre-cooked items.
- **Baking Basics**: Flour, sugar, baking powder, and related ingredients.

**Categorization Method**:

- Inclusion Keywords: Specific keywords identified within product_name determine category assignment (e.g., "rice" and "bread" for "Staples").
- Exclusion Keywords: Certain keywords prevent misclassification (e.g., excluding "chocolate" from "Staples" ensures "chocolate cake" is not incorrectly categorized).


## Summary Statistics

### Product Count by Category and Vendor
The distribution of products across categories and vendors provides insight into the variety available to students.
@tbl-product-counts

```{r}
#| label: tbl-product-counts
#| tbl-cap: "Number of Products by Category and Vendor"
#| echo: false
#| message: false
#| warning: false
#| tbl-pos: H

# Create a summary table of product counts
product_counts <- grocery_data %>%
  group_by(category, vendor) %>%
  summarise(Count = n(), .groups = "drop") %>%
  pivot_wider(names_from = vendor, values_from = Count, values_fill = 0)

# Format the table
product_counts_formatted <- product_counts %>%
  mutate(across(where(is.numeric), ~ formatC(., format = "d", big.mark = ",")))

# Display the summary table
kable(product_counts_formatted, caption = "Number of Products by Category and Vendor") %>%
  kable_styling(latex_options = c("hold_position"))

```


### Price Distribution by Vendor
Understanding the price distribution helps identify pricing patterns across supermarkets.
@fig-price-distribution

```{r}
#| label: fig-price-distribution
#| fig-cap: "Price Distribution by Vendor"
#| echo: false
#| message: false
#| warning: false
#| fig-pos: H

# Filter data to include only prices from 0 to 25
grocery_data_filtered <- subset(grocery_data, current_price >= 0 & current_price <= 25)

# Plot price distribution by vendor
p <- ggplot(grocery_data_filtered, aes(x = current_price, fill = vendor)) +
  geom_histogram(binwidth = 0.5, alpha = 0.8, position = "identity", color = "white") +  # Increased alpha for more vibrant colors
  facet_wrap(~vendor, ncol = 3) +
  theme_minimal() +
  labs(x = "Price ($)", y = "Frequency", title = "Price Distribution by Vendor (0-25$)") +
  scale_fill_manual(values = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF", "#FF61C3")) +  # Using bright custom colors
  theme(
    legend.position = "none",
    strip.background = element_rect(fill = "#e0e0e0", color = NA),  # Light background for facet labels
    strip.text = element_text(face = "bold", color = "#444444")  # Bold facet label text for emphasis
  ) +
  scale_x_continuous(limits = c(0, 25))  # Limiting x-axis to the range of 0 to 25

print(p)
```


### Average Price by Category and Vendor
Comparing the average prices shows which supermarkets are more economical for specific categories.
@tbl-average-prices

```{r}
#| label: tbl-average-prices
#| tbl-cap: "Average Price by Category and Vendor"
#| echo: false
#| message: false
#| warning: false
#| tbl-pos: H

# Calculate average prices
average_prices <- grocery_data %>%
  group_by(category, vendor) %>%
  summarise(Average_Price = mean(current_price, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = vendor, values_from = Average_Price)

# Format the average prices
average_prices_formatted <- average_prices %>%
  mutate(across(where(is.numeric), ~ sprintf("$%.2f", .)))

# Display the average prices table
kable(average_prices_formatted, caption = "Average Price by Category and Vendor") %>%
  kable_styling(latex_options = c("hold_position"))

```


### Price Comparison Across Categories
Visualizing the average prices helps identify trends and outliers.
@fig-average-price-by-category

```{r}
#| label: fig-average-price-by-category
#| fig-cap: "Average Price by Category and Vendor"
#| echo: false
#| message: false
#| warning: false
#| fig-pos: H

# Prepare data for plotting
average_prices_long <- grocery_data %>%
  group_by(category, vendor) %>%
  summarise(Average_Price = mean(current_price, na.rm = TRUE), .groups = "drop")

# Plot average price by category and vendor
ggplot(average_prices_long, aes(x = category, y = Average_Price, fill = vendor)) +
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  theme_minimal() +
  labs(x = "Category", y = "Average Price ($)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set2")

```


# Model {#sec-model}

## Model Formulation

We utilized a Bayesian linear regression model to evaluate the effect of supermarket vendor on product prices, controlling for product category. The model is formulated as follows:

$$
\text{current\_price}_i = \alpha + \beta_1 \times \text{vendor}_i + \beta_2 \times \text{category}_i + \epsilon_i
$$

Where:

- $\text{current\_price}_i$ is the price of product $i$ in Canadian dollars (CAD).
- $\text{vendor}_i$ represents the supermarket vendor for product $i$.
- $\text{category}_i$ denotes the product category for product $i$.
- $\alpha$ is the intercept term.
- $\beta_1$ and $\beta_2$ are coefficients indicating the effect of vendor and category, respectively.
- $\epsilon_i$ is the error term, assumed to be normally distributed with mean 0 and variance $\sigma^2$.

## Model Justification

A Bayesian linear regression was selected for its ability to incorporate prior information and provide a probabilistic interpretation of the model parameters [@citeRstanarm]. This approach is suitable for continuous outcome variables like product prices and allows for a comprehensive assessment of uncertainty in the estimates.

Including both vendor and category as predictors enables us to isolate the impact of the supermarket on pricing while accounting for variations across different product types. This aligns with the study's objective to determine whether Metro's 10% student discount effectively reduces grocery costs for students.

## Priors and Assumptions

We assigned non-informative priors to the model parameters to let the data primarily inform the posterior distributions:

$$
\alpha \sim \text{Normal}(0, 100)
$$
$$
\beta_1 \sim \text{Normal}(0, 100)
$$
$$
\beta_2 \sim \text{Normal}(0, 100)
$$
$$
\sigma \sim \text{Uniform}(0, 100)
$$

These priors are broad enough to not impose strong constraints on the parameter estimates, reflecting minimal prior knowledge about the relationships.


# Results {#sec-result}

Our analysis results are summarized in  @tbl-modelresults. The Bayesian linear regression model indicates significant differences in product prices across different supermarket vendors and product categories.

## Model Summary
Table 1: @tbl-modelresults : Bayesian Linear Regression Model Estimates

```{r}
#| tbl-modelresults, echo = FALSE, message = FALSE, warning = FALSE, tbl.pos = 'H'

# Create a summary table using modelsummary
modelsummary(
  model,
  stars = FALSE,
  gof_omit = "AIC|BIC|Log.Lik|RMSE",
  output = "latex",
  title = "Bayesian Linear Regression Model Estimates",
  fmt = 2
)
```

## Interpretation of Model Estimates
The intercept \( \alpha = 7.4\) represents the baseline price for products in the reference category (**Staples**) at the reference vendor (**Metro**). Coefficients for each vendor indicate the average price difference compared to **Metro**, while coefficients for each category reflect the average price difference compared to **Staples**.

### Vendor Effects

- **Galleria**: Products are priced higher by $3.7 CAD compared to Metro.
- **Loblaws**: Products are priced higher by $0.9 CAD compared to Metro.
- **No Frills**: Products are priced lower by $0.4 CAD compared to Metro.
- **T&T Supermarket**: Products are priced higher by $0.8 CAD compared to Metro.

### Category Effects

- **Condiments**: Products are priced lower by $1.2 CAD compared to Staples.
- **Dairy**: Products are priced higher by $0.4 CAD compared to Staples.
- **Frozen Essentials**: Products are priced lower by $2.8 CAD compared to Staples.
- **Fruits**: Products are priced lower by $2.0 CAD compared to Staples.
- **Proteins**: Products are priced higher by $0.6 CAD compared to Staples.
- **Snacks**: Products are priced lower by $0.2 CAD compared to Staples.
- **Spices**: Products are priced lower by $1.4 CAD compared to Staples.
- **Vegetables**: Products are priced lower by $1.9 CAD compared to Staples.

### Visualizing Coefficient Estimates @fig-coef-estimates
Figure @fig-coef-estimates): Coefficient Estimates with 90% Credibility Intervals

```{r}
#| label: fig-coef-estimates
#| fig-cap: "Coefficient Estimates with 90% Credibility Intervals"
#| echo: false
#| message: false
#| warning: false
#| fig-pos: H

# Extract posterior samples as a matrix
posterior_samples <- as.matrix(model)

# Convert the matrix to a data frame for manipulation
posterior_df <- as.data.frame(posterior_samples)

# Reshape the data frame from wide to long format
posterior_long <- posterior_df %>%
  pivot_longer(cols = everything(), names_to = "term", values_to = "value")

# Compute summary statistics: mean, 5th percentile, 95th percentile
coef_summary <- posterior_long %>%
  group_by(term) %>%
  summarize(
    estimate = mean(value),
    conf.low = quantile(value, 0.05),
    conf.high = quantile(value, 0.95)
  ) %>%
  filter(!(term %in% c("sigma")))  # Exclude 'sigma' if present

# Create a new column to indicate predictor type
coef_summary <- coef_summary %>%
  mutate(
    type = case_when(
      grepl("^vendor", term) ~ "Vendor",
      grepl("^category", term) ~ "Category",
      TRUE ~ "Other"
    )
  )

# Reorder the terms based on the estimate for better visualization
coef_summary <- coef_summary %>%
  arrange(estimate) %>%
  mutate(term = factor(term, levels = term))

# Define distinct, famous colors for each predictor type
# Vendors: Blue (#1f78b4)
# Categories: Red (#e31a1c)
# Other: Green (#33a02c) - in case there are any
color_palette <- c("Vendor" = "#1f78b4",   # Blue
                   "Category" = "#e31a1c", # Red
                   "Other" = "#33a02c")    # Green

# Plot the coefficients with their 90% credibility intervals
ggplot(coef_summary, aes(x = estimate, y = reorder(term, estimate), color = type)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2, size = 1) +
  scale_color_manual(values = color_palette) +
  theme_minimal(base_size = 14) +
  theme(
    legend.title = element_blank(),
    legend.position = "top",
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    axis.title.y = element_blank()
  ) +
  labs(
    title = "Coefficient Estimates with 90% Credibility Intervals",
    x = "Estimate (CAD)"
  )
```
@fig-coef-estimates illustrates the 90% credibility intervals for each coefficient. Credibility intervals for No Frills, Galleria, Loblaws, and T&T Supermarket do not overlap with zero, indicating that their effects on product prices are statistically significant. Similarly, several product categories, including protein, staple, condoinment, sipice, and vegetable have credibility intervals that do not overlap with zero, confirming significant differences from the reference category (Staples).

## Model Validation
Model diagnostics, including convergence checks and posterior predictive checks, are presented in Appendix A. The trace plots and Rhat values indicate good convergence of the Markov Chain Monte Carlo (MCMC) sampling, with all Rhat values below 1.05. Posterior predictive checks demonstrate that the model adequately fits the data, capturing the distribution of product prices across vendors and categories.


# Discussion {#sec-discussion}

In this study, I examined whether Metro's 10% student discount offers genuine savings for University of Toronto (UofT) students compared to nearby supermarkets like No Frills, Loblaws, Galleria, and T&T Supermarket. Using Bayesian linear regression and exploratory data analysis (EDA), I compared prices across different vendors and product categories.

## Implications of Findings

### Maximizing Savings

Metro's discount effectively lowers prices for staples, proteins, and dairy. However, No Frills generally has lower base prices across more categories, such as condiments and frozen essentials. This suggests that students can save more by shopping at No Frills for most items and using Metro's discount for specific categories.

### Budget Management

While Metro's discount alone may not drastically cut expenses, the combined savings over time are significant. For students who value convenience or need specific products, Metro remains a good option despite some higher prices. Additionally, loyalty programs from stores like Loblaws and Galleria offer extra savings through points or cashback, sometimes even exceeding Metro's discount in certain areas.

### Reflections on Exploratory Data Analysis

The EDA provided clear insights into pricing across different supermarkets. Visual tools like boxplots and heatmaps helped identify where each store is most competitive. These visualizations make it easier for students to decide where to shop based on their needs and budgets.

## Limitations

### Data Quality

Some products were miscategorized, which could slightly bias the results. Future studies should aim for more accurate categorization.

### Temporal Constraints

Prices can change due to seasons or promotions. A longer study period would give a better picture of pricing trends.

### Geographic Specificity

This study focused on supermarkets near UofT. Expanding to other areas could determine if these trends hold elsewhere.

### Discount Awareness

Not all students may be aware of or able to use Metro's discount, affecting its overall benefit.

## Future Research

Future studies could track prices over a longer period, include a broader range of products, and explore how student awareness and behavior influence shopping choices. Additionally, comparing supermarkets in different regions would enhance the generalizability of the findings.

## Conclusion

Metro's 10% student discount provides meaningful savings in certain categories, but No Frills offers lower prices across a wider range of products. For UofT students looking to manage their grocery budgets effectively, a mixed shopping strategy—using No Frills for most purchases and Metro for specific discounted items—can maximize savings. Combining this approach with loyalty programs can further reduce expenses, helping students make smarter financial decisions.


\newpage

# Appendix

## Surveys, sampling, and observational data

Our study relies on observational data collected from Project Hammer, an initiative aimed at enhancing competition in the Canadian grocery sector by compiling historical price data from major grocers' websites [@Filipp2024]. The dataset spans from February 28, 2024, to the most recent date available, including vendors such as Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart Canada, and Save-On-Foods.

### Data Collection Method
The data was gathered through web scraping of online platforms, focusing on "in-store pickup" options within a Toronto neighborhood. Initially, the collection targeted a limited set of products but expanded over time to encompass a broader range of items across various categories. The data fields include:

- **Timestamps** (`nowtime`)
- **Vendor names** (`vendor`)
- **Unique product identifiers** per vendor (`product_id`)
- **Product descriptions** (`product_name`)
- **Brand names** (`brand`)
- **Quantities or sizes** (`units`)
- **Current selling prices** after discounts (`current_price`)
- **Previous prices** indicating discounts (`old_price`)
- **Price per unit measures** (`price_per_unit`)
- **Additional details** such as stock status or promotional indicators (`other`)

### Sampling Methodology
We employed a convenience sampling approach, collecting data based on product availability on vendor websites at the time of scraping. While this method facilitated efficient data acquisition, it introduces potential biases that may affect the validity and generalizability of our findings.

### R packages used for analysis

In this study, various R packages were used for data processing, visualization, analysis, and reporting. The @thereferencecanbewhatever, including @dplyr, @readr, and @stringr, was used for data cleaning and manipulation. Visualizations were created using @ggplot2 and improved with @patchwork and @cowplot, with color scales from @viridis. Statistical modeling was done with @citeRstanarm, diagnostic plots with @bayesplot, and summaries with @broom and @modelsummary. File paths were managed using @here, and Parquet files were handled with @arrow. Reporting used @knitr and @kableExtra. Code quality was maintained using @testthat, @lintr, and @styler.

### Potential Biases and Limitations

- **Selection Bias**: Since the sample consists of products readily available or prominently displayed online, certain items may be overrepresented or underrepresented. Popular products or those heavily promoted by vendors are more likely to appear in the dataset, while niche or less-advertised items may be omitted [@Thompson2012].

- **Temporal Bias**: Prices were captured at specific points in time, which may not reflect fluctuations due to promotions, stock levels, or seasonal changes. This limitation could lead to inaccurate assessments of pricing trends if data collection coincided with atypical pricing periods [@Groves2009].

- **Geographical Limitation**: Focusing on a single Toronto neighborhood restricts the applicability of our results to other regions. Price variations across different areas or provinces are not accounted for, which may influence the overall analysis of the Canadian grocery market.

- **Vendor Representation**: The extent of online catalogs varies among vendors. Those with more extensive online offerings might skew the data, affecting the balance of product representation across different retailers.

### Impact on Study Findings
These biases can influence the outcomes of our analysis. For instance:

- **Selection Bias** may result in an overestimation or underestimation of average prices if the sample does not accurately reflect the diversity of products available in the market.
- **Temporal Bias** could misrepresent pricing dynamics, leading to erroneous conclusions about trends or patterns in grocery pricing.

### Addressing Sampling Limitations
To enhance the robustness of our study, several strategies can be implemented:

- **Stratified Sampling**: Adopting a stratified sampling method would involve dividing the population into homogeneous subgroups (strata) based on characteristics such as vendor, product category, or price range. By ensuring proportional representation from each stratum, we can reduce selection bias and improve the representativeness of the sample [@Groves2009].

- **Geographical Diversification**: Expanding data collection to include multiple neighborhoods or cities across Canada would address geographical limitations. This approach would capture regional pricing differences and provide a more comprehensive view of the national grocery market.

- **Randomized Temporal Sampling**: Collecting data at various times and dates, including different days of the week and times of the day, would mitigate temporal bias. This strategy accounts for time-based variations such as weekend promotions or weekday price adjustments.

- **Data Weighting**: Applying statistical weights to the data based on known distributions of products or sales volumes can adjust for overrepresented or underrepresented items. Data weighting helps align the sample more closely with the true population characteristics [@Smith2018].

### Simulation of Improved Sampling Methods
To assess the potential impact of enhanced sampling techniques, we conducted a simulation comparing convenience sampling with stratified random sampling. Using the existing dataset, we simulated stratified samples by grouping products according to vendor and category, then randomly selecting items proportionally from each group.

### Simulation Findings
- **Reduced Variance**: The stratified samples exhibited lower variance in average prices compared to the convenience sample, suggesting more stable and reliable estimates.
- **Improved Representativeness**: Stratified sampling better captured the diversity of products and vendors, leading to findings that are more reflective of the overall market.
- **Enhanced Generalizability**: The results from the stratified samples showed trends and patterns consistent with national pricing data reported by other sources, indicating greater applicability beyond the initial geographic focus.

### Linkages to Literature
The limitations associated with convenience sampling are well-documented in survey methodology literature. Non-probabilistic sampling methods can introduce significant biases, undermining the accuracy of statistical inferences [@Thompson2012]. Groves et al. (2009) emphasize the importance of probability-based sampling to enhance the validity of survey results, particularly in studies aiming to inform policy or market interventions [@Groves2009].

In the context of observational data, drawing causal inferences is inherently challenging due to confounding factors and lack of randomization. Smith and Piette (2018) recommend robust sampling designs and analytical methods to mitigate biases, enabling more reliable conclusions from observational studies [@Smith2018].

### Recommendations for Future Research
To address the identified limitations and strengthen future studies, we suggest the following:

- **Implement Probability-Based Sampling**: Transitioning to stratified random sampling or other probabilistic methods would enhance the representativeness of the data.
- **Expand Geographic Scope**: Including multiple regions across Canada would provide a more accurate reflection of national grocery pricing trends.
- **Increase Temporal Coverage**: Collecting data over different periods, including various seasons and promotional cycles, would capture temporal variations in pricing.
- **Incorporate Additional Variables**: Gathering data on factors such as in-store promotions, stock levels, and customer demographics could enrich the analysis and control for confounding variables.
- **Data Validation and Cross-Referencing**: Comparing collected data with alternative sources, such as point-of-sale systems or official market reports, would help verify accuracy and reliability.

By addressing these areas, future research can offer more definitive insights into pricing strategies and competition within the Canadian grocery sector, ultimately informing policies and initiatives aimed at benefiting consumers.


## Data Details

### Raw Data

```{r tab-raw-data-preview, echo=FALSE, message=FALSE, warning=FALSE, tab.cap="Preview of the Grocery Prices Dataset", tab.pos="H"}

# Preview of the raw data
raw_data_preview <- grocery_data %>%
  select(product_id, product_name, category, vendor, current_price) %>%
  slice(1:5)

# Display the table
kable(raw_data_preview, caption = "Preview of the Grocery Prices Dataset") %>%
  kable_styling(latex_options = c("hold_position"))
```

### Data Features

```{r tab-data-features, echo=FALSE, message=FALSE, warning=FALSE, tab.cap="Features of the Grocery Prices Dataset", tab.pos="H"}
# Description of data features
data_features <- tibble(
  Feature = c("product_id", "product_name", "category", "vendor", "current_price"),
  Description = c(
    "Unique identifier for each product.",
    "Name or description of the product.",
    "Category of the product (e.g., staples, proteins, dairy).",
    "Vendor offering the product (e.g., Metro, No Frills).",
    "Current selling price of the product after any discounts."
  )
)

# Display the table
kable(data_features, caption = "Features of the Grocery Prices Dataset") %>%
  kable_styling(latex_options = c("hold_position"))
```

## Data Visualization

### Figure A1: Distribution of Current Prices

```{r fig-current-price-distribution, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Distribution of Current Prices Across All Products", fig.pos="H"}
# Load necessary libraries
library(ggplot2)

# Plot the distribution of current prices
ggplot(grocery_data, aes(x = current_price)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white", alpha = 0.7) +
  labs(
    title = "Distribution of Current Prices Across All Products",
    x = "Current Price (CAD)",
    y = "Number of Products"
  ) +
  theme_minimal(base_size = 12)
```

### Figure A2: Price Distribution by Vendor and Category

```{r fig-price-distribution-category, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Price Distribution by Vendor and Category", fig.pos="H"}
# Plot price distribution by vendor and category
ggplot(grocery_data, aes(x = vendor, y = current_price, fill = vendor, color = vendor)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, width = 0.6) +
  geom_jitter(width = 0.2, alpha = 0.6, size = 0.7) + # Adjusted alpha and size for visibility
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Dark2") + # Add a distinct palette for points
  labs(
    title = "Price Distribution by Vendor and Category",
    x = "Vendor",
    y = "Price (CAD)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  ) +
  facet_wrap(~ category, scales = "free_y")
```

## Model Details

### MCMC Diagnostics

#### Rhat Values

```{r tab-rhat-values, echo=FALSE, message=FALSE, warning=FALSE, tab.cap="Rhat Values for Model Parameters", tab.pos="H"}
# Extract the stan_summary from the model
stan_summary <- model$stan_summary

# Extract Rhat values and parameter names
rhat_values <- stan_summary[, "Rhat"]
parameter_names <- rownames(stan_summary)

# Create a data frame
rhat_df <- data.frame(
  Parameter = parameter_names,
  Rhat = as.numeric(rhat_values)
)

# Remove any NA values (if present)
rhat_df <- rhat_df[!is.na(rhat_df$Rhat), ]

# Display Rhat values in a table without styling
kable(
  rhat_df,
  digits = 4,
  caption = "Rhat Values for Model Parameters"
)

```

#### Trace Plots

```{r fig-trace-plots, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Trace Plots for Selected Parameters", fig.pos="H"}

# Extract MCMC samples
mcmc_samples <- as.array(model)

# Select parameters to plot
parameters_to_plot <- c("(Intercept)", "vendorNoFrills", "vendorLoblaws", "categorydairy")

# Generate trace plots
trace_plots <- mcmc_trace(mcmc_samples, pars = parameters_to_plot) +
  theme_minimal(base_size = 12)

# Display trace plots
print(trace_plots)
```

### Residuals vs Fitted Values

```{r fig-residuals-vs-fitted, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Residuals vs Fitted Values", fig.pos="H"}
# Extract fitted values and residuals
fitted_values <- fitted(model)
residuals <- resid(model)

# Create a residuals vs fitted plot
ggplot(data = data.frame(Fitted = fitted_values, Residuals = residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal(base_size = 12)
```

## Conclusion

The appendix provides additional details on the data and the model used in the analysis. The MCMC diagnostics, including Rhat values and trace plots, indicate good convergence of the model parameters. The residuals vs fitted values plot does not show any obvious patterns, suggesting that the linear model is appropriate for the data.


\newpage


# References


